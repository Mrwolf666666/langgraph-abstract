from langgraph.graph import StateGraph
from node.abstractNode import abstract_node
from node.polishNode import polish_node
from node.checkNode import check_node
from node.modifyNode import modify_node
from messageState.agentState import AgentState
from edge.checkConditionEdges import check_route_condition
import uuid
from langgraph.graph import END


def build_abstract_agent(state: AgentState):
    "构建摘要智能体"
    # 创建图
    work_flow = StateGraph(AgentState)
    # 添加节点
    work_flow.add_node("abstractNode", abstract_node)  # 摘要
    work_flow.add_node("polishNode", polish_node)  # 润色
    work_flow.add_node("checkNode", check_node)  # 审查
    work_flow.add_node("modifyNode",modify_node) # 修改

    # 设置入口点
    work_flow.set_entry_point("abstractNode")

    # 添加边
    work_flow.add_edge("abstractNode", "polishNode")
    work_flow.add_edge("polishNode", "checkNode")
    work_flow.add_conditional_edges(
        "checkNode",
        check_route_condition,
        {
            "modifyNode": "modifyNode",
            END: END
        }
    )
    work_flow.add_edge("modifyNode","checkNode")

    # 编译并运行
    app = work_flow.compile()
    # 生成任务ID
    task_id = str(uuid.uuid4())
    state['task_id'] = task_id
    result = app.invoke(state)
    print(f"摘要智能体运行结果为：{result}")


if __name__ == '__main__':
    original_text = '''
    教育、制造、金融行业的三位实践者，来分享他们的RAG落地经验梦晨 发自 凹非寺量子位 | 公众号 QbitAI每一次，当基础模型能力变强，总会有人预言：RAG（检索增强生成）或许要过时了。但目前为止，每一次，这种预言都已落空。比如今年2月，当第一批百万上下文长度模型出现的时候，有人说KV缓存会取代RAG。后来大模型Agent突飞猛进的时候，又有人说10年就是以嵌入为基础的RAG的最后期限。10年毕竟太远，现在很难说得清楚。但有RAG存在的未来，已经业内有不少人正在积极规划：产业界，英伟达等巨头亲自下场挖掘RAG价值。学术界，最前沿领域Agent与RAG的结合，开始被越来越多的人探讨。为什么？当大模型从实验室走向工厂车间、企业办公楼、教育课堂、金融后台、数据中心机房的那一刻，它需要的不止是语言理解与生成能力，还需要“读懂”企业内部海量而更新频繁的数据资源。训练本身昂贵且缓慢，大模型本体无法频繁更新，但企业知识与数据却在日新月异。RAG正是企业数据接入大模型的数据枢纽，而将数据接入AI成为大模型时代最重要的事——它帮助大模型实时获取最新、最契合业务场景的知识，让AI真正成为能干活、有脑子的行业助手。换句话说，是因为RAG正在各行各业为大模型落地扫清障碍。这里分别有教育、制造、金融行业的三位实践者，来分享他们的RAG落地经验。先来看教育行业，特点是对知识更新迭代的需求尤其强烈。在教育行业有个常见的场景：如教研资料、题库、学科内容不断变化，仅靠训练底层模型难以与日新月异的教学信息同步。且学生提问较泛且不标准，传统关键字检索方案解决也行不通。这时RAG成为低成本、高灵活性缓解大模型幻觉问题的最佳解决方案。因此，行业通用做法就期望使用RAG开发框架打造智能助手，从而发挥海量课程、试题资源的数据价值，快速、准确地回答学生提问，提高在线教学效果，减少人力成本。某教企最初尝试过开源的RAG方案，然而却发现其效果不佳，构建起来也繁琐。后来在腾讯云团队的帮助下，该教企客户基于腾讯云向量数据库进行RAG方案的落地优化，他们终于实现了在复杂、多样、动态知识库中高效检索。过程中处理“QA对”数据的问题，给工程师留下深刻印象：一开始语义分析的效果不是很好，经常会把多个QA对拆裂了，导致询问A问题，得到B问题的答案。后来与腾讯云团队后来讨论出解决方案，通过定制化逻辑修正文本拆分偏差，从而得到精准检索结果。这让教企无需频繁更新大模型本身，就能让大模型实时取用最新教研资料，给用户提供可信、更新及时的答案。腾讯云向量数据库基于大量客户有RAG应用开发的需求，还推出了AI套件功能：一站式文档检索解决方案，支持用户直接上传原始文档，数分钟内即可快速构建专属知识库，大幅提高知识接入效率。在合作过程中，客户也高度评价腾讯云技术支持的快速响应与产品迭代能力，体现了其技术实力和灵活性。过去可能需要几十分钟甚至上小时的查询，如今只需秒级响应。在教育场景中，RAG与向量数据库的结合，不仅提高检索效率，更让企业积累的教育资源充分释放价值，为学生与老师带来更高质量的智能化学习体验。相比教育行业，制造业更显复杂。这里有数量庞大的技术标准、设计资料、工程图纸，还有多种多样的文档格式和数据来源，电子档、扫描件、表格、图片、CAD文档……这些文档往往分散在各个系统、部门和节点，查找、核对和更新成本高昂。工程师培养周期长达3-5年，技术标准不断迭代，一旦出现生产问题，快速定位解决方案简直是“大海捞针”。RAG可以帮大模型整合行业知识，但首先要解决电器行业文档多、内容复杂、图文表混排的问题，不能只有向量数据库和开发接口，还要整合端到端产品和服务。腾讯云大模型知识引擎，基于大语言模型的知识应用开发平台，提供知识问答、知识总结等应用模版及原子能力，助力企业低门槛构建企业级知识服务。让大模型能够回答较为普世的问题，如服务于垂直专业领域，会存在知识深度和时效性不足的问题。腾讯云大模型知识引擎帮助万榕信息打造了从原始文档中迅速获取标准和最佳实践，工程师不再耗费半天去翻阅标准合同、设计资料，而是几分钟内就能定位信息；碰到南网高海拔产品设计标准、断路器事故处理等棘手问题，AI助手根据RAG动态检索企业内部知识库、归纳处理意见，并生成报告初稿。过去的流程极度依赖资深工程师的个人经验，如今RAG让知识得以系统化传承、动态更新和快速分享。这不仅缩短了新人工程师的上手周期（从1.5年缩短至6-8个月），还直接提升了整体工作效率（在人员不变的情况下，目标是提高40%的效率）。RAG在制造业中带来的，是效率、成本和人才培育模式的全方位革新。金融科技是一个极其注重合规、安全与隐私的行业。招商证券作为金融行业的龙头企业，正全面拥抱AI，自上而下地推进数字化转型。他们将“AI编程助手”作为AI技术应用的重要切入点，主要原因在于：在这样的背景下，简单的RAG方案远不足以满足需求，需要大模型、产品、基础设施等全面整合，提供私有化部署的解决方案。腾讯云AI代码助手提供产品基础能力及开放式架构，为招商证券打造智能化金融科技研发工具。腾讯云基于内部经验开发AI代码助手，通过插件形式解决开发痛点，为企业和团队提供效率提升的解决方案，同时注重灵活部署与行业需求适配依托腾讯云的技术方案，招商证券实现了工具集成、数据安全和隐私保护，解决了金融业在AI应用落地中“好用不好管”的难题，让AI代码助手切实提高研发效率，满足日益增长的业务和监管要求。双方的合作甚至深入到产品之外：在推广AI代码助手的过程中，招商证券与腾讯云都面临了技术变革与习惯转型的挑战。参考腾讯云内部推广AI代码助手的经验，招商证券的推广分为两个阶段：第一阶段通过主动推广取得了初步成效；第二阶段打造体系化的推广运营机制，实现开发者自发地接受并使用AI工具。目前，招商证券已有千余名开发人员使用AI代码助手，日活跃人数达300，代码采纳率接近20%。招商证券希望AI代码助手能够扩展到更多垂直领域，如量化交易、模型定价、分析师等业务人员，覆盖更广泛的代码应用场景。其实，上面三个案例均来自AICon全球人工智能大会《Techo Day-RAG应用与实践》专场。各行业技术大咖们，现场交流分享了探索RAG在解决大模型幻觉中的创新策略与实战经验。我们注意到，这些行业成功案例的背后都有身影同一个身影，腾讯云。比如前面某教企分享过的业务初期尝试开源方案未果，转而与腾讯云团队合作解决了语义分析中的问题拆分错误的等难题。但为什么是腾讯云？为了回答这个问题，我们也请到了腾讯云数据库副总经理罗云分享他的观点：一是长期技术积累和内部验证。腾讯云向量数据库并在腾讯内部已广泛应用，包括腾讯视频的版权与合规检索等苛刻场景中早已成熟运转。自2019年持续研发，为满足深度神经网络和向量检索融合的业务需求，腾讯云不断打磨向量数据库，并在实践中推动存储与计算分离架构的落地。这些技术与经验让腾讯云能够在面对多样化、复杂化的客户需求时快速响应、持续改进。二是丰富的服务生态与快速迭代能力。某教企在实现车辆安全相关QA问题时，需要定制化处理拆分逻辑——腾讯云团队快速介入、灵活解决。万榕信息需要处理从标准文档到扫描件的多模态数据，腾讯云知识引擎也能给出针对性解决方案。对于招商证券这种高度合规与高定制的场景，腾讯云则提供从基础数据库、到私有化部署与产品级能力的一整套方案。总结起来就是，这样的稳定性与灵活性的并存的RAG能力，在大模型加速落地的关键阶段尤为宝贵。未来，随着产业对AI的要求不断升级，RAG本身也将持续演进。技术创新会进一步提高检索效率、提升多模态数据处理能力、降低用户使用门槛；更多场景将在RAG的赋能下实现智能化转型。因此，当下质疑RAG过时为时尚早。RAG不仅不会消亡，反而将伴随大模型技术的深度落地而愈发重要。在下一阶段的AI竞争中，谁能让大模型“用得起来”、数据“用得其所”、业务“跑得更快”，谁就能在产业智能的浪潮中占得先机。
    '''
    state_input: AgentState = {
        "task_id": "",
        "original_text": original_text,
        "abstract_text": "",
        "polish_text": "",
        "check_result": 0,
        "check_reason": ""
    }
    build_abstract_agent(state_input)

